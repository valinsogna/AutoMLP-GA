{'nb_neurons': 1024, 'nb_layers': 6, 'activation': 'LeakyReLU', 'optimizer': 'rmsprop', 'lr_scheduler': 'linear', 'initial_lr': 0.0001, 'batch_size': 256, 'dropout': 0.1}
0.9776
--------------------------------------------------------------------------------
{'nb_neurons': 640, 'nb_layers': 3, 'activation': 'Sigmoid', 'optimizer': 'rmsprop', 'lr_scheduler': 'none', 'initial_lr': 0.001, 'batch_size': 256, 'dropout': 0}
0.9778
--------------------------------------------------------------------------------
